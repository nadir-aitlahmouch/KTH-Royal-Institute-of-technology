{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vae_ml.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPGeIJ2RjHn0LlNYf9CUI5+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"nHWPXTnFBtDI"},"source":["# **Functions that load and binarize our data (if not already binarized) into .amat files**"]},{"cell_type":"code","metadata":{"id":"z0LoPIFkVczP","executionInfo":{"status":"ok","timestamp":1610667614426,"user_tz":-60,"elapsed":624,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["# from __future__ import print_function\n","# import torch\n","# import torch.utils.data as data_utils\n","# import numpy as np\n","# from scipy.io import loadmat\n","# import os\n","# import pickle\n","\n","\n","# def load_omniglot(batch_size, n_validation=1345):\n","\n","#     # start processing\n","#     def reshape_data(data):\n","#         return data.reshape((-1, 28, 28)).reshape((-1, 28*28), order='F') #modifié order \"F\" au lieu de fortran\n","#     omni_raw = loadmat(os.path.join('/content/', 'chardata.mat'))\n","\n","#     # train and test data\n","#     train_data = reshape_data(omni_raw['data'].T.astype('float32'))\n","#     x_test = reshape_data(omni_raw['testdata'].T.astype('float32'))\n","\n","#     # shuffle train data\n","#     np.random.shuffle(train_data)\n","\n","#     # set train and validation data\n","#     x_train = train_data[:-n_validation]\n","#     x_val = train_data[-n_validation:]\n","\n","\n","#     # binarize\n","#     np.random.seed(777)\n","#     x_train = np.random.binomial(1, x_train) # ajouté\n","#     x_val = np.random.binomial(1, x_val)\n","#     x_test = np.random.binomial(1, x_test)\n","\n","#     print(x_train.shape)\n","#     print(x_val.shape)\n","\n","#     train_file = open(\"/content/omniglot_train.amat\", \"w\")\n","#     valid_file = open(\"/content/omniglot_valid.amat\", \"w\")\n","\n","#     for i in range(23000):\n","#       for j in range(784):\n","#         if j != 783:\n","#           train_file.write(str(x_train[i][j]))\n","#           train_file.write(\" \")\n","#         else:\n","#           train_file.write(str(x_train[i][j]))\n","#       train_file.write(\"\\n\")\n","\n","#     for i in range(1345):\n","#       for j in range(784):\n","#         if j != 783:\n","#           valid_file.write(str(x_val[i][j]))\n","#           valid_file.write(\" \")\n","#         else:\n","#           valid_file.write(str(x_val[i][j]))\n","#       valid_file.write(\"\\n\")\n","\n","#     train_file.close()\n","#     valid_file.close()\n","\n","#     # return train, val\n","\n","\n","# # ======================================================================================================================\n","# def load_caltech101silhouettes():\n","#     # start processing\n","#     def reshape_data(data):\n","#         return data.reshape((-1, 28, 28)).reshape((-1, 28*28), order='F')\n","#     caltech_raw = loadmat(os.path.join('/content/', 'caltech101_silhouettes_28.mat'))\n","\n","#     # train, validation and test data\n","#     x_train = 1. - reshape_data(caltech_raw['train_data'].astype('float32'))\n","#     np.random.shuffle(x_train)\n","#     x_val = 1. - reshape_data(caltech_raw['val_data'].astype('float32'))\n","#     np.random.shuffle(x_val)\n","#     x_test = 1. - reshape_data(caltech_raw['test_data'].astype('float32'))\n","\n","#     print(1 in x_train)\n","\n","#     print(x_train.shape)\n","#     print(x_val.shape)\n","\n","#     train_file = open(\"/content/caltech101_train.amat\", \"w\")\n","#     valid_file = open(\"/content/caltech101_valid.amat\", \"w\")\n","\n","#     for i in range(4100):\n","#       for j in range(784):\n","#         if j != 783:\n","#           train_file.write(str(int(x_train[i][j])))\n","#           train_file.write(\" \")\n","#         else:\n","#           train_file.write(str(int(x_train[i][j])))\n","#       train_file.write(\"\\n\")\n","\n","#     for i in range(2264):\n","#       for j in range(784):\n","#         if j != 783:\n","#           valid_file.write(str(int(x_val[i][j])))\n","#           valid_file.write(\" \")\n","#         else:\n","#           valid_file.write(str(int(x_val[i][j])))\n","#       valid_file.write(\"\\n\")\n","\n","#     train_file.close()\n","#     valid_file.close()\n","\n","# # ======================================================================================================================\n","# def load_freyfaces(TRAIN = 1565, VAL = 200, TEST = 200):\n","#     # set args\n","#     # args.input_size = [1, 28, 20]\n","\n","#     # start processing\n","#     with open('/content/freyfaces.pkl', 'rb') as f:\n","#         data = pickle.load(f)\n","\n","#     data = (data[0] + 0.5) / 256.\n","\n","#     # shuffle data:\n","#     np.random.shuffle(data)\n","\n","#     # train images\n","#     x_train = data[0:TRAIN].reshape(-1, 28*20)\n","#     # validation images\n","#     x_val = data[TRAIN:(TRAIN + VAL)].reshape(-1, 28*20)\n","#     # test images\n","#     x_test = data[(TRAIN + VAL):(TRAIN + VAL + TEST)].reshape(-1, 28*20)\n","\n","#     print(x_train.shape)\n","#     print(x_val.shape)\n","\n","#     # train_file = open(\"/content/freyfaces_train.amat\", \"w\")\n","#     # valid_file = open(\"/content/freyfaces_valid.amat\", \"w\")\n","\n","#     # for i in range():\n","#     #   for j in range():\n","#     #     if j != 783:\n","#     #       train_file.write(str(int(x_train[i][j])))\n","#     #       train_file.write(\" \")\n","#     #     else:\n","#     #       train_file.write(str(int(x_train[i][j])))\n","#     #   train_file.write(\"\\n\")\n","\n","#     # for i in range():\n","#     #   for j in range():\n","#     #     if j != 783:\n","#     #       valid_file.write(str(int(x_val[i][j])))\n","#     #       valid_file.write(\" \")\n","#     #     else:\n","#     #       valid_file.write(str(int(x_val[i][j])))\n","#     #   valid_file.write(\"\\n\")\n","\n","#     # train_file.close()\n","#     # valid_file.close()\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5-JIyKMW1iy","executionInfo":{"status":"ok","timestamp":1610667614660,"user_tz":-60,"elapsed":850,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["# from keras.datasets import fashion_mnist\n","# import numpy as np\n","# # load dataset\n","\n","# def load_fashionMNIST():\n","#     (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n","\n","#     print(x_train.shape)\n","#     print(x_test.shape)\n","\n","#     train_file = open(\"/content/fashionMNIST_train.amat\", \"w\")\n","#     valid_file = open(\"/content/fashionMNIST_valid.amat\", \"w\")\n","\n","#     for i in range(60000):\n","#       for j in range(28):\n","#         for k in range(28):\n","#           v = int(x_train[i][j][k])/255\n","#           if v > 0.5:\n","#             v = 1\n","#           else:\n","#             v = 0\n","#           if j != 27 or k != 27:\n","#             train_file.write(str(v))\n","#             train_file.write(\" \")\n","#           else:\n","#             train_file.write(str(v))\n","#       train_file.write(\"\\n\")\n","\n","#     for i in range(10000):\n","#       for j in range(28):\n","#         for k in range(28):\n","#           v = int(x_test[i][j][k])/255\n","#           if v > 0.5:\n","#             v = 1\n","#           else:\n","#             v = 0          \n","#           if j != 27 or k != 27:\n","#             valid_file.write(str(v))\n","#             valid_file.write(\" \")\n","#           else:\n","#             valid_file.write(str(v))\n","#       valid_file.write(\"\\n\")\n","\n","#     train_file.close()\n","#     valid_file.close()\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ldt4IYGLBeFC"},"source":["---\n","# **VAE**"]},{"cell_type":"markdown","metadata":{"id":"0NxP0ZNBvlhC"},"source":["# **Imports**"]},{"cell_type":"code","metadata":{"id":"BMJRTr1Z4mM9","executionInfo":{"status":"ok","timestamp":1610667616834,"user_tz":-60,"elapsed":3018,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import functools\n","import os\n","import numpy as np\n","import tensorflow.compat.v1 as tf\n","import tensorflow_probability as tfp\n","tfd = tfp.distributions\n","\n","shape_image = [28, 28, 1]"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gxa24__T7zp1"},"source":["---\n","# **Encoder and decoder functions**"]},{"cell_type":"code","metadata":{"id":"Wv4bJp1D4wuy","executionInfo":{"status":"ok","timestamp":1610667616837,"user_tz":-60,"elapsed":3018,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["def create_encoder(activation, latent_size, base_depth):\n","  \"\"\"Creates the encoder function\"\"\"\n","  conv = functools.partial(\n","      tf.keras.layers.Conv2D, padding=\"SAME\", activation=activation)\n","\n","  encoder_net = tf.keras.Sequential([\n","      conv(base_depth, 5, 1),\n","      conv(base_depth, 5, 2),\n","      conv(2 * base_depth, 5, 1),\n","      conv(2 * base_depth, 5, 2),\n","      conv(4 * latent_size, 7, padding=\"VALID\"),\n","      tf.keras.layers.Flatten(),\n","      tf.keras.layers.Dense(2 * latent_size, activation=None),\n","  ])\n","\n","  def encoder(images):\n","    images = 2 * tf.cast(images, dtype=tf.float32) - 1\n","    net = encoder_net(images)\n","    return tfd.MultivariateNormalDiag(\n","        loc=net[..., :latent_size],\n","        scale_diag=tf.nn.softplus(net[..., latent_size:] + tf.math.log(tf.math.expm1(1.0))),\n","        name=\"code\")\n","\n","  return encoder\n","\n","#_______________________________________________________________________________\n","\n","def create_decoder(activation, latent_size, output_shape, base_depth):\n","  \"\"\"Creates the decoder function\"\"\"\n","  deconv = functools.partial(\n","      tf.keras.layers.Conv2DTranspose, padding=\"SAME\", activation=activation)\n","  conv = functools.partial(\n","      tf.keras.layers.Conv2D, padding=\"SAME\", activation=activation)\n","\n","  decoder_net = tf.keras.Sequential([\n","      deconv(2 * base_depth, 7, padding=\"VALID\"),\n","      deconv(2 * base_depth, 5),\n","      deconv(2 * base_depth, 5, 2),\n","      deconv(base_depth, 5),\n","      deconv(base_depth, 5, 2),\n","      deconv(base_depth, 5),\n","      conv(output_shape[-1], 5, activation=None),\n","  ])\n","\n","  def decoder(codes):\n","    original_shape = tf.shape(input=codes)\n","    codes = tf.reshape(codes, (-1, 1, 1, latent_size))\n","    logits = decoder_net(codes)\n","    logits = tf.reshape(\n","        logits, shape=tf.concat([original_shape[:-1], output_shape], axis=0))\n","    return tfd.Independent(tfd.Bernoulli(logits=logits),\n","                           reinterpreted_batch_ndims=len(output_shape),\n","                           name=\"image\")\n","\n","  return decoder"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dKzJFy-Z76Eg"},"source":["---\n","# **Mixture function**"]},{"cell_type":"code","metadata":{"id":"AMpXvDL0vjv-","executionInfo":{"status":"ok","timestamp":1610667616838,"user_tz":-60,"elapsed":3016,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["def mixture_prior(latent_size, mixture_components):\n","  \"\"\"Creates the mixture of Gaussians prior distribution\"\"\"\n","  if mixture_components == 1:\n","    return tfd.MultivariateNormalDiag(\n","        loc=tf.zeros([latent_size]),\n","        scale_identity_multiplier=1.0)\n","\n","  loc = tf.compat.v1.get_variable(\n","      name=\"loc\", shape=[mixture_components, latent_size])\n","  raw_scale_diag = tf.compat.v1.get_variable(\n","      name=\"raw_scale_diag\", shape=[mixture_components, latent_size])\n","  mixture_logits = tf.compat.v1.get_variable(\n","      name=\"mixture_logits\", shape=[mixture_components])\n","\n","  return tfd.MixtureSameFamily(\n","      components_distribution=tfd.MultivariateNormalDiag(\n","          loc=loc,\n","          scale_diag=tf.nn.softplus(raw_scale_diag)),\n","      mixture_distribution=tfd.Categorical(logits=mixture_logits),\n","      name=\"prior\")\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sTHq8q-K-gv_"},"source":["---\n","# **Helpers for image vizualisation in Tensorboard**"]},{"cell_type":"code","metadata":{"id":"3xup_YB8-cqh","executionInfo":{"status":"ok","timestamp":1610667616839,"user_tz":-60,"elapsed":3013,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["def assemble_images(images, rows, cols):\n","  \"\"\"Helper utility to make a field of images.\"\"\"\n","  shape = tf.shape(input=images)\n","  width = shape[-3]\n","  height = shape[-2]\n","  depth = shape[-1]\n","  images = tf.reshape(images, (-1, width, height, depth))\n","  batch = tf.shape(input=images)[0]\n","  rows = tf.minimum(rows, batch)\n","  cols = tf.minimum(batch // rows, cols)\n","  images = images[:rows * cols]\n","  images = tf.reshape(images, (rows, cols, width, height, depth))\n","  images = tf.transpose(a=images, perm=[0, 2, 1, 3, 4])\n","  images = tf.reshape(images, [1, rows * width, cols * height, depth])\n","  return images\n","\n","\n","def image_summary(name, tensor, rows=8, cols=8):\n","  tf.compat.v1.summary.image(\n","      name, assemble_images(tensor, rows, cols), max_outputs=1)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3uyREHau9yeT"},"source":["---\n","# **Model for estimator**"]},{"cell_type":"code","metadata":{"id":"s1FIEY-B9x_I","executionInfo":{"status":"ok","timestamp":1610667616840,"user_tz":-60,"elapsed":3012,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["def model_vae(features, labels, mode, params, config):\n","  \"\"\"Builds the model function for use in an estimator\"\"\"\n","\n","  latent_prior = mixture_prior(params[\"latent_size\"],params[\"mixture_components\"])\n","  encoder = create_encoder(params[\"activation\"],params[\"latent_size\"],\n","                         params[\"base_depth\"])\n","  decoder = create_decoder(params[\"activation\"],params[\"latent_size\"],\n","                         shape_image,\n","                         params[\"base_depth\"])\n","\n","  image_summary(\n","      \"input\", tf.cast(features, dtype=tf.float32), rows=1, cols=16)\n","\n","  approx_posterior = encoder(features)\n","  approx_posterior_sample = approx_posterior.sample(params[\"n_samples\"])\n","  decoder_likelihood = decoder(approx_posterior_sample)\n","  image_summary(\n","      \"recon/sample\",\n","      tf.cast(decoder_likelihood.sample()[:3, :16], dtype=tf.float32),\n","      rows=3,\n","      cols=16)\n","  image_summary(\n","      \"recon/mean\",\n","      decoder_likelihood.mean()[:3, :16],\n","      rows=3,\n","      cols=16)\n","\n","\n","  LogLikelihood = decoder_likelihood.log_prob(features)\n","  average_LL = tf.reduce_mean(input_tensor=LogLikelihood)\n","  tf.compat.v1.summary.scalar(\"Loglikelihood\", average_LL)\n"," \n","  KL = (approx_posterior.log_prob(approx_posterior_sample)\n","            - latent_prior.log_prob(approx_posterior_sample))\n","  \n","  average_KL = tf.reduce_mean(input_tensor=KL)\n","  tf.compat.v1.summary.scalar(\"KL\", average_KL)\n","\n","\n","  elbo_l = LogLikelihood - KL\n","\n","  elbo = tf.reduce_mean(input_tensor=elbo_l)\n","  loss = -elbo\n","  tf.compat.v1.summary.scalar(\"Elbo\", elbo)\n","\n","\n","  random_image = decoder(latent_prior.sample(16))\n","  image_summary(\n","      \"random/sample\",\n","      tf.cast(random_image.sample(), dtype=tf.float32),\n","      rows=4,\n","      cols=4)\n","  image_summary(\"random/mean\", random_image.mean(), rows=4, cols=4)\n","\n","\n","  # Perform variational inference by minimizing the -ELBO.\n","  global_step = tf.compat.v1.train.get_or_create_global_step()\n","  learning_rate = tf.compat.v1.train.cosine_decay(\n","      params[\"learning_rate\"], global_step, params[\"max_steps\"])\n","  tf.compat.v1.summary.scalar(\"learning_rate\", learning_rate)\n","  optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n","  train_op = optimizer.minimize(loss, global_step=global_step)\n","\n","  return tf.estimator.EstimatorSpec(\n","      mode=mode,\n","      loss=loss,\n","      train_op=train_op,\n","      eval_metric_ops={\n","          \"Elbo\":\n","              tf.compat.v1.metrics.mean(elbo),\n","          \"KL\":\n","              tf.compat.v1.metrics.mean(average_KL),\n","          \"Loglikelihood\":\n","              tf.compat.v1.metrics.mean(average_LL),\n","      },\n","  )"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mk1FV74z-5MS"},"source":["---\n","# **Loads data and creating iterators**"]},{"cell_type":"code","metadata":{"id":"0EqhK09i5AZH","executionInfo":{"status":"ok","timestamp":1610667616841,"user_tz":-60,"elapsed":3010,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["def load(directory, filename):\n","  \"\"\"Loads a file.\"\"\"\n","  filepath = os.path.join(directory, filename)\n","  if tf.io.gfile.exists(filepath):\n","    return filepath\n","\n","def binary_dataset(filename):\n","  \"\"\"Returns binary static tf.data.Dataset.\"\"\"\n","  amat_file = load(\"/content/\", filename)\n","  dataset = tf.data.TextLineDataset(amat_file)\n","  str_to_arr = lambda string: np.array([c == b\"1\" for c in string.split()])\n","\n","  def _parser(s):\n","    booltensor = tf.compat.v1.py_func(str_to_arr, [s], tf.bool)\n","    reshaped = tf.reshape(booltensor, [28, 28, 1])\n","    return tf.cast(reshaped, dtype=tf.float32), tf.constant(0, tf.int32)\n","\n","  return dataset.map(_parser)\n","\n","\n","def build_input(data, batch_size):\n","  \"\"\"Builds an Iterator switching between train and heldout data.\"\"\"\n","  training = \"\"\n","  validation = \"\"\n","  if data == \"MNIST\":\n","    training = \"binarized_mnist_train.amat\"\n","    validation = \"binarized_mnist_valid.amat\"\n","  elif data == \"FashionMNIST\":\n","    training = \"fashionMNIST_train.amat\"\n","    validation = \"fashionMNIST_valid.amat\"\n","  elif data == \"Omniglot\":\n","     training = \"omniglot_train.amat\"\n","     validation = \"omniglot_valid.amat\"\n","  elif data == \"Caltech101\":\n","     training = \"caltech101_train.amat\"\n","     validation = \"caltech101_valid.amat\"\n","\n","  # Build an iterator over training batches.\n","  def train_input():\n","    dataset = binary_dataset(training)\n","    dataset = dataset.shuffle(50000).repeat().batch(batch_size)\n","    return tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n","\n","  # Build an iterator over the heldout set.\n","  def eval_input():\n","    eval_dataset = binary_dataset(validation)\n","    eval_dataset = eval_dataset.batch(batch_size)\n","    return tf.compat.v1.data.make_one_shot_iterator(eval_dataset).get_next()\n","\n","  return train_input, eval_input\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nvl87pM7_DvI"},"source":["---\n","# **Main function**\n","\n"]},{"cell_type":"code","metadata":{"id":"fFOY_E8l_EMI","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1610668348490,"user_tz":-60,"elapsed":734642,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}},"outputId":"32a4aeda-753f-451d-ed03-c6c0871aa53b"},"source":["def main(argv):\n","  print(\"=================================================> Declaration of parameters training\")\n","  params = {}\n","  params[\"learning_rate\"] = 0.001\n","  params[\"max_steps\"] = 5000\n","  params[\"latent_size\"] = 16\n","  params[\"base_depth\"] = 32\n","  params[\"activation\"] = getattr(tf.nn, \"leaky_relu\")\n","  params[\"batch_size\"] = 32\n","  params[\"n_samples\"] = 100\n","  params[\"mixture_components\"] = 10\n","  params[\"viz_steps\"] = 2000\n","  \n","  print(params)\n","\n","\n","  # Creating iterators on our data\n","  train_input, eval_input = build_input(\"MNIST\", params[\"batch_size\"])\n","\n","  # Defining our estimator\n","  estimator = tf.estimator.Estimator(model_vae,params=params,\n","      config=tf.estimator.RunConfig(\n","          model_dir=\"/content/Results\",\n","          save_checkpoints_steps=params[\"viz_steps\"],\n","          )\n","      )\n","\n","  # Traing the estimator\n","  print(\"=================================================> Begining training\")\n","  estimator.train(train_input, steps=params[\"viz_steps\"])\n","  print(\"=================================================> Finished training\")\n","\n","  # Evaluating the results\n","  print(\"=================================================> Evaluating the results\")\n","  eval_results = estimator.evaluate(eval_input)\n","\n","  print(\"Evaluation_results:\\n\\t%s\\n \" % eval_results)\n","\n","\n","if __name__ == \"__main__\":\n","  tf.compat.v1.app.run()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["=================================================> Declaration of parameters training\n","{'learning_rate': 0.001, 'max_steps': 5000, 'latent_size': 16, 'base_depth': 32, 'activation': <function leaky_relu at 0x7fe40b94e620>, 'batch_size': 32, 'n_samples': 100, 'mixture_components': 10, 'viz_steps': 2000}\n","INFO:tensorflow:Using config: {'_model_dir': '/content/Results', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 2000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:39.563933 140618697717632 estimator.py:191] Using config: {'_model_dir': '/content/Results', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 2000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"},{"output_type":"stream","text":["=================================================> Begining training\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stdout"},{"output_type":"stream","text":["W0114 23:39:39.588899 140618697717632 deprecation.py:339] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-8-9aecf18b1aa0>:14: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n"],"name":"stdout"},{"output_type":"stream","text":["W0114 23:39:40.972617 140618697717632 deprecation.py:339] From <ipython-input-8-9aecf18b1aa0>:14: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:41.000286 140618697717632 estimator.py:1162] Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:175: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not pass `graph_parents`.  They will  no longer be used.\n"],"name":"stdout"},{"output_type":"stream","text":["W0114 23:39:41.024057 140618697717632 deprecation.py:537] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:175: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Do not pass `graph_parents`.  They will  no longer be used.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:42.331437 140618697717632 estimator.py:1164] Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:42.336336 140618697717632 basic_session_run_hooks.py:546] Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:42.667500 140618697717632 monitored_session.py:246] Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:46.937231 140618697717632 session_manager.py:505] Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:46.953830 140618697717632 session_manager.py:508] Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:47.689029 140618697717632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 0...\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /content/Results/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:47.692051 140618697717632 basic_session_run_hooks.py:618] Saving checkpoints for 0 into /content/Results/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:39:47.889691 140618697717632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 0...\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 545.9817, step = 0\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:40:03.316751 140618697717632 basic_session_run_hooks.py:262] loss = 545.9817, step = 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 3.26017\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:40:33.989143 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 3.26017\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 178.2593, step = 100 (30.677 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:40:33.993398 140618697717632 basic_session_run_hooks.py:260] loss = 178.2593, step = 100 (30.677 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 3.12976\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:41:05.940429 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 3.12976\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 140.84827, step = 200 (31.954 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:41:05.947032 140618697717632 basic_session_run_hooks.py:260] loss = 140.84827, step = 200 (31.954 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 3.01534\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:41:39.104177 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 3.01534\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 127.63057, step = 300 (33.165 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:41:39.111677 140618697717632 basic_session_run_hooks.py:260] loss = 127.63057, step = 300 (33.165 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.98609\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:42:12.592768 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.98609\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 117.212395, step = 400 (33.485 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:42:12.596522 140618697717632 basic_session_run_hooks.py:260] loss = 117.212395, step = 400 (33.485 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 3.03839\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:42:45.504931 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 3.03839\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 128.34663, step = 500 (32.912 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:42:45.508651 140618697717632 basic_session_run_hooks.py:260] loss = 128.34663, step = 500 (32.912 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.99552\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:43:18.888203 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.99552\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 102.867195, step = 600 (33.387 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:43:18.895228 140618697717632 basic_session_run_hooks.py:260] loss = 102.867195, step = 600 (33.387 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 3.00221\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:43:52.196970 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 3.00221\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 112.660255, step = 700 (33.307 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:43:52.202513 140618697717632 basic_session_run_hooks.py:260] loss = 112.660255, step = 700 (33.307 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 3.0055\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:44:25.469272 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 3.0055\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 104.56201, step = 800 (33.269 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:44:25.471851 140618697717632 basic_session_run_hooks.py:260] loss = 104.56201, step = 800 (33.269 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.99701\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:44:58.835822 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.99701\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 105.06627, step = 900 (33.368 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:44:58.840279 140618697717632 basic_session_run_hooks.py:260] loss = 105.06627, step = 900 (33.368 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.9982\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:45:32.189162 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.9982\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 101.92599, step = 1000 (33.355 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:45:32.195701 140618697717632 basic_session_run_hooks.py:260] loss = 101.92599, step = 1000 (33.355 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 3.00233\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:46:05.496575 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 3.00233\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 97.96272, step = 1100 (33.307 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:46:05.502833 140618697717632 basic_session_run_hooks.py:260] loss = 97.96272, step = 1100 (33.307 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.99161\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:46:38.923428 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.99161\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 95.7298, step = 1200 (33.425 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:46:38.927748 140618697717632 basic_session_run_hooks.py:260] loss = 95.7298, step = 1200 (33.425 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.99212\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:47:12.344528 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.99212\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 95.52571, step = 1300 (33.424 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:47:12.351579 140618697717632 basic_session_run_hooks.py:260] loss = 95.52571, step = 1300 (33.424 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.98702\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:47:45.822716 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.98702\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 100.8052, step = 1400 (33.478 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:47:45.829855 140618697717632 basic_session_run_hooks.py:260] loss = 100.8052, step = 1400 (33.478 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.98829\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:48:19.286669 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.98829\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 102.237015, step = 1500 (33.461 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:48:19.290992 140618697717632 basic_session_run_hooks.py:260] loss = 102.237015, step = 1500 (33.461 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.99055\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:48:52.725354 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.99055\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 93.728165, step = 1600 (33.441 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:48:52.732435 140618697717632 basic_session_run_hooks.py:260] loss = 93.728165, step = 1600 (33.441 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.99528\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:49:26.111224 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.99528\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 99.73911, step = 1700 (33.385 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:49:26.117251 140618697717632 basic_session_run_hooks.py:260] loss = 99.73911, step = 1700 (33.385 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.99998\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:49:59.444714 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.99998\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 96.2876, step = 1800 (33.330 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:49:59.447369 140618697717632 basic_session_run_hooks.py:260] loss = 96.2876, step = 1800 (33.330 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.99904\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:50:32.788776 140618697717632 basic_session_run_hooks.py:702] global_step/sec: 2.99904\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 99.433235, step = 1900 (33.348 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:50:32.795506 140618697717632 basic_session_run_hooks.py:260] loss = 99.433235, step = 1900 (33.348 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:05.761021 140618697717632 basic_session_run_hooks.py:614] Calling checkpoint listeners before saving checkpoint 2000...\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 2000 into /content/Results/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:05.763034 140618697717632 basic_session_run_hooks.py:618] Saving checkpoints for 2000 into /content/Results/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:05.921427 140618697717632 basic_session_run_hooks.py:626] Calling checkpoint listeners after saving checkpoint 2000...\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 97.73491.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:06.003162 140618697717632 estimator.py:350] Loss for final step: 97.73491.\n"],"name":"stderr"},{"output_type":"stream","text":["=================================================> Finished training\n","=================================================> Evaluating the results\n","INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:06.043182 140618697717632 estimator.py:1162] Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:07.188677 140618697717632 estimator.py:1164] Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2021-01-14T23:51:07Z\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:07.213981 140618697717632 evaluation.py:255] Starting evaluation at 2021-01-14T23:51:07Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:07.372030 140618697717632 monitored_session.py:246] Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /content/Results/model.ckpt-2000\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:07.380878 140618697717632 saver.py:1292] Restoring parameters from /content/Results/model.ckpt-2000\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:07.541404 140618697717632 session_manager.py:505] Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:07.565362 140618697717632 session_manager.py:508] Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Inference Time : 43.54881s\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:50.764148 140618697717632 evaluation.py:273] Inference Time : 43.54881s\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2021-01-14-23:51:50\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:50.765678 140618697717632 evaluation.py:276] Finished evaluation at 2021-01-14-23:51:50\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 2000: Elbo = -97.20989, KL = 23.684874, Loglikelihood = -73.52507, global_step = 2000, loss = 97.20989\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:50.772319 140618697717632 estimator.py:2066] Saving dict for global step 2000: Elbo = -97.20989, KL = 23.684874, Loglikelihood = -73.52507, global_step = 2000, loss = 97.20989\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /content/Results/model.ckpt-2000\n"],"name":"stdout"},{"output_type":"stream","text":["I0114 23:51:51.016448 140618697717632 estimator.py:2127] Saving 'checkpoint_path' summary for global step 2000: /content/Results/model.ckpt-2000\n"],"name":"stderr"},{"output_type":"stream","text":["Evaluation_results:\n","\t{'Elbo': -97.20989, 'KL': 23.684874, 'Loglikelihood': -73.52507, 'loss': 97.20989, 'global_step': 2000}\n"," \n"],"name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\n"]},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"mO99k8yh_Pc7"},"source":["---\n","# **Tensorboard**"]},{"cell_type":"code","metadata":{"id":"SZtEqt2p4rR-","executionInfo":{"status":"aborted","timestamp":1610668348485,"user_tz":-60,"elapsed":734635,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["logdir = \"/content/Results/\"\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n","\n","%load_ext tensorboard \n","\n","%tensorboard --logdir /content/Results/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LxSOeW1u-Oz2","executionInfo":{"status":"aborted","timestamp":1610668348487,"user_tz":-60,"elapsed":734634,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["!rm -r /content/Results/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jyj6l7okO-pc","executionInfo":{"status":"aborted","timestamp":1610668348488,"user_tz":-60,"elapsed":734632,"user":{"displayName":"Nadir Ait Lahmouch","photoUrl":"","userId":"11663709753394591698"}}},"source":["# import matplotlib.pyplot as plt\n","# from google.colab import files\n","\n","# LL = [-73.70, -73.59, -73.99, -75.34, -74.62, -74.43, -73.70, -73.96, -74.55, -73.94, -73.34, -74.20]\n","# mix = [5, 10, 20, 40, 60, 80, 100, 150, 200, 300, 400, 500]\n","# plt.plot(mix, LL, linewidth=4.0)\n","# plt.xlabel(\"Number of components\")\n","# plt.ylabel(\"Log Likelihood\")\n","# plt.grid()\n","\n","# plt.savefig(\"nbcomp.png\", bbox_inches='tight')\n","# files.download(\"nbcomp.png\") "],"execution_count":null,"outputs":[]}]}